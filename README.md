# ğŸ¯ Job Crawler API

Uma API universal para coletar vagas de emprego de diferentes job boards de forma automatizada.

## ğŸ“‹ Sobre o Projeto

Este projeto Ã© um web scraper especializado em coletar vagas de emprego de diferentes plataformas de recrutamento, centralizando todas as informaÃ§Ãµes em uma Ãºnica API. Atualmente, suportamos as seguintes plataformas:

### Portais Suportados

- âœ… Gupy
- âœ… Lever
- âœ… Greenhouse
- âœ… Workable
- âœ… BambooHR
- âœ… Breezy
- âœ… iCIMS
- âœ… Recruitee
- âœ… Factorial
- âœ… Abler
- âœ… Compleo
- âœ… Enlizt
- âœ… Gupy
- âœ… HiringRoom
- âœ… Inhire
- âœ… PandaP
- âœ… Quickin
- âœ… Recrut.ai
- âœ… Recrutei

## ğŸš€ Funcionalidades

- Scraping automÃ¡tico e em tempo real de vagas
- Sistema de cache para otimizaÃ§Ã£o de requisiÃ§Ãµes
- Suporte a mÃºltiplas plataformas de vagas
- Filtros personalizÃ¡veis (cargo, localizaÃ§Ã£o, empresa)
- API RESTful documentada com Swagger
- ExportaÃ§Ã£o de dados em JSON e CSV

## ğŸ› ï¸ Tecnologias Utilizadas

- Node.js
- TypeScript
- Express
- Playwright (para web scraping)
- Swagger UI (documentaÃ§Ã£o da API)
- Docker

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

### PrÃ©-requisitos

- Node.js 14+
- npm ou yarn
- Docker (recomendado)

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio
```bash
git clone https://github.com/joaogsantosc/job-crawler-api.git
```

2. Instale as dependÃªncias
```bash
npm install
```

3. Configure as variÃ¡veis de ambiente
```bash
cp .env.example .env.local
```

4. Inicie o servidor
```bash
npm run dev
```

## ğŸš€ Deploy

### Desenvolvimento Local com Docker

```bash
# Iniciar em modo desenvolvimento
npm run docker:dev

# Ou manualmente
docker-compose -f docker-compose.dev.yml up
```

### ProduÃ§Ã£o com Docker

```bash
# Build e iniciar em produÃ§Ã£o
npm run docker:prod

# Ou manualmente
docker-compose up
```

### VariÃ¡veis de Ambiente
Crie um arquivo `.env` com:

```env
FIRECRAWL_API_KEY=sua_chave_api
FIRECRAWL_API_URL=url_da_api
```

## ğŸ“š DocumentaÃ§Ã£o da API

A documentaÃ§Ã£o completa estÃ¡ disponÃ­vel via Swagger UI em:
```
http://localhost:3001/api-docs
```

### Endpoints Principais

- `GET /scraper-job` - Lista todas as vagas disponÃ­veis
- `GET /job-details` - Retorna as informaÃ§Ãµes das vagas de qualquer plataforma (ex: gupy, workable, lever)

---

Desenvolvido com â¤ï¸ por [JoÃ£o Santos](https://github.com/joaogsantosc)
```
